{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is an exemplar which demonstrates transferring zip files between a Box folder and Savio scratch to run OCR on images using Tesseract (inside a Singularity container)\n",
    "\n",
    "( tested with boxsdk (2.0.0a2) on python 3.5 kernel)\n",
    "pip install -Iv boxsdk==2.0.0a2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_This software is available under the terms of the Educational Community License, Version 2.0 (ECL 2.0). This software is Copyright 2016 The Regents of the University of California, Berkeley (\"Berkeley\")._\n",
    "\n",
    "The text of the ECL license is reproduced below.\n",
    "\n",
    "Educational Community License, Version 2.0\n",
    "*************************************\n",
    "Copyright 2016 The Regents of the University of California, Berkeley (\"Berkeley\")\n",
    "\n",
    "Educational Community License, Version 2.0, April 2007\n",
    "\n",
    "The Educational Community License version 2.0 (\"ECL\") consists of the\n",
    "Apache 2.0 license, modified to change the scope of the patent grant in\n",
    "section 3 to be specific to the needs of the education communities using\n",
    "this license. The original Apache 2.0 license can be found at:[http://www.apache.org/licenses/LICENSE-2.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook configuration section\n",
    "Set of target and source directories, script file names and other used as parameters in processing below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "boxProjectFolder = 'Court Downloads Ayotte Ellias'\n",
    "boxResultsFolder = 'OCR-zips'\n",
    "boxFileList = ['7.zip', '80003.zip', '605.zip']\n",
    "\n",
    "projectname = 'chench_test3_7_80003_605'\n",
    "runFolder = '/global/scratch/mmanning/chench/'\n",
    "\n",
    "tesseractimage = '/global/scratch/mmanning/tesseract4.img'\n",
    "tesseractdatadir = '/opt/tessdata/'\n",
    "pdfnamelist = []\n",
    "\n",
    "scratchDataDirectory = '/global/scratch/mmanning/chench/test3/'\n",
    "tesseractScratchDataDirectory = '/scratch/'\n",
    "\n",
    "SINGULARITYCMD = 'singularity exec -B /global/scratch/mmanning/chench/test3/:/scratch/  /global/scratch/mmanning/tesseract4.img'\n",
    "\n",
    "gsCommandScript = runFolder + 'gsCommandScript.sh'\n",
    "t4CommandScript = runFolder + 't4CommandScript.sh'\n",
    "slurmScript = runFolder + 'slurmscript.sh'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Authorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to store the oauth2 refresh token in a local file. This can be modified to use a keychain or other as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def store_tokens(access_token, refresh_token):\n",
    "    \n",
    "    \"\"\"Callback for storing refresh tokens. (For now we ignore access tokens).\"\"\"\n",
    "    with open('apptoken.cfg', 'w') as f:\n",
    "     f.write(refresh_token.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oauth2 information is read from a local file with three lines, one line per parameter. \n",
    "The client id and client secret are defined in the Box application created for this notebook.  Create the application at the Box Developers site: https://berkeley.app.box.com/developers/services/edit/\n",
    "\n",
    "The redirect uri can be any site that requires validation. Run the bootstrap notebook to create initial \n",
    "tokens that are then continually refreshed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "CLIENT_ID = None\n",
    "CLIENT_SECRET = None\n",
    "REDIRECT_URI = None\n",
    "\n",
    "# folder where box token config file resides\n",
    "os.chdir('/global/home/users/mmanning')\n",
    "\n",
    "\n",
    "# Read app info from text file\n",
    "with open('app.cfg', 'r') as app_cfg:\n",
    "    CLIENT_ID = app_cfg.readline()\n",
    "    CLIENT_SECRET = app_cfg.readline()\n",
    "    REDIRECT_URI = app_cfg.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The refresh token is read from a local file. This token was created by running the bootstrap notebook which requires the user to validate with CalNet Authentication Service credentials, then stores the returned auth and refresh tokens in the same config files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REFRESH_TOKEN = None\n",
    "\n",
    "# Read app info from text file\n",
    "with open('apptoken.cfg', 'r') as apptoken_cfg:\n",
    "    REFRESH_TOKEN = apptoken_cfg.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Perform autentication__ \n",
    "then create globus client\n",
    "Verify client is working by retrieving the name of the users root folder in Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from boxsdk import OAuth2\n",
    "from boxsdk import Client\n",
    "\n",
    "# Do OAuth2 authorization.\n",
    "oauth = OAuth2(\n",
    "    client_id=CLIENT_ID.strip(),\n",
    "    client_secret=CLIENT_SECRET.strip(),\n",
    "    refresh_token=REFRESH_TOKEN.strip(),\n",
    "    store_tokens=store_tokens\n",
    ")\n",
    "\n",
    "client = Client(oauth)\n",
    "\n",
    "root_folder = client.folder(folder_id='0').get()\n",
    "print (\"folder name: \", root_folder['name'] )\n",
    "\n",
    "items = client.folder(folder_id='0').get_items(limit=100, offset=0)\n",
    "#print (\"items: \", items )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__function to find folder id be folder name.__  \n",
    "Current SDK does not have a 'find by name' function so must loop thru all folders and look for match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_folder_id(folder_name):\n",
    "    folderlist = client.search(query=folder_name, result_type='folder', limit=10, offset=0)\n",
    "    \n",
    "    if len(folderlist) == 0 or len(folderlist) > 1:\n",
    "        print('folder not found: ', folder_name)\n",
    "        return 0\n",
    "    else:\n",
    "        return folderlist[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def natural_sort_key(s, _nsre=re.compile('([0-9]+)')):\n",
    "    return [int(text) if text.isdigit() else text.lower()\n",
    "            for text in re.split(_nsre, s)]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__function to return all files in directory tree.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scandir import scandir\n",
    "import os\n",
    "def scantreeForFiles(path):\n",
    "    \"\"\"Recursively yield DirEntry objects for given directory.\"\"\"\n",
    "    for entry in scandir(path):\n",
    "        if entry.is_dir(follow_symlinks=False):\n",
    "            yield from scantree(entry.path) \n",
    "        else:\n",
    "            yield entry.path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__function to return list of all folders in directory tree.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scandir import scandir\n",
    "import os\n",
    "def scandirForFolders(path, dirlist):\n",
    "    \"\"\"Recursively yield DirEntry objects for given directory.\"\"\"\n",
    "    for entry in scandir(path):\n",
    "        if entry.is_dir(follow_symlinks=False):\n",
    "            dirlist.append(entry.path)\n",
    "            scandirForFolders(entry.path, dirlist)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Validate all the task log files produced by ht_helper __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validateTaskResults(fileroot, totalTasks):\n",
    "    # file root is job-name.jobId.taskNumber.log\n",
    "    \n",
    "    errorList = []\n",
    "    \n",
    "    for i in range(0, totalTasks-1):\n",
    "        fn = fileroot + '.' + str(i)\n",
    "        if os.path.exists(fn):\n",
    "            out = !tail -1 {fn}\n",
    "            retval = out[0]\n",
    "            #print ('return code: ', out[0])\n",
    "        else:\n",
    "            print ('warning: log file not available: ', fn)\n",
    "        \n",
    "        if ( retval != '0' ):\n",
    "            errorList.append(i)\n",
    "            \n",
    "    return errorList\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the file(s)  from the Box folder.\n",
    "currently the Box SDK does not have an option for finding a folder by name so if you are looking for a specific folder then you would need to loop thru all the items in the list below and do a name match. Once you find the folder and retrieve the id, you can save that id for subsequent runs. Another option is to get the id from the url in the web client, but approah below is more flexible for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil \n",
    "\n",
    "\n",
    "os.chdir(scratchDataDirectory)\n",
    "print ('current working directory: ', os.getcwd())\n",
    "\n",
    "# test folder contents\n",
    "items = client.folder(folder_id='0').get_items(limit=20, offset=0)\n",
    "if type(items) is list:\n",
    "    print ('number of files in top folder: ', len(items) )\n",
    "    \n",
    "    targetfolderId = ''\n",
    "    for item in items:\n",
    "        if item['type'] == 'folder':\n",
    "            print('folder name: ', item['name'])\n",
    "            if item['name'] == boxProjectFolder:\n",
    "                targetfolderId = item['id']\n",
    "                print('targetfolderId: ', targetfolderId)\n",
    "        \n",
    "    if targetfolderId is not None:\n",
    "        tgtitems = client.folder(folder_id=targetfolderId).get_items(limit=200, offset=0)\n",
    "        if type(tgtitems) is list:\n",
    "            print ('number of files in target folder: ', len(tgtitems) ) \n",
    "        \n",
    "        # download files\n",
    "        for tgtitem in tgtitems:\n",
    "            if  not tgtitem['type'] == 'folder' and tgtitem['name'] in boxFileList:\n",
    "                print('downloading: ', tgtitem['name'])\n",
    "                newfile = open(scratchDataDirectory + tgtitem['name'], 'wb')\n",
    "                client.file(file_id=tgtitem['id']).download_to(newfile)\n",
    "                newfile.close()\n",
    "        print('downloading completed. ')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__unzip the files__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "def unzip(source_filename, dest_dir):\n",
    "    with zipfile.ZipFile(source_filename) as zf:\n",
    "        print('extractall: ', source_filename)\n",
    "        zf.extractall(dest_dir)\n",
    "    print('extractall completed. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "for filename in glob.glob('*.zip'):\n",
    "    print('unzip: ', filename)\n",
    "    unzip(filename, scratchDataDirectory)\n",
    "    #remove the zip file\n",
    "    os.remove(filename)\n",
    "print('zip processing completed. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__SLURM job script__ normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# batch script\n",
    "batchtemplate = '#!/bin/bash -l  \\n\\\n",
    "# Job name: \\n\\\n",
    "#SBATCH --job-name=' + projectname + '\\n\\\n",
    "# \\n\\\n",
    "# Account: \\n\\\n",
    "#SBATCH --account=ac_scsguest \\n\\\n",
    "# \\n\\\n",
    "# Partition: \\n\\\n",
    "#SBATCH --partition=savio2 \\n\\\n",
    "# \\n\\\n",
    "## Scale by increasing the number of nodes \\n\\\n",
    "#SBATCH --nodes=5  \\n\\\n",
    "## DO NOT change ntasks-per-node setting as T4 also distributes across cores \\n\\\n",
    "#SBATCH --ntasks-per-node=6 \\n\\\n",
    "#SBATCH --qos=savio_normal \\n\\\n",
    "# \\n\\\n",
    "# Wall clock limit: \\n\\\n",
    "#SBATCH --time={} \\n\\\n",
    "# \\n\\\n",
    "## Command(s) to run: \\n\\\n",
    "module load gcc openmpi  \\n\\\n",
    "/global/home/groups/allhands/bin/ht_helper.sh  -t {} -n1 -s1 -vL \\n' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove special characters from filenames__  \n",
    "not sure what characters to include here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "for entry in scantreeForFiles(scratchDataDirectory):\n",
    "    filename, file_extension = os.path.splitext(entry)\n",
    "    if ( entry.endswith('.pdf') and re.search('\\$', entry)):\n",
    "        print ('sprcial characters in filename: ', entry)\n",
    "        os.rename(entry, re.sub(\"[\\$]\", \"\", entry))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create script to convert all pdf files in working directory to images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__need to handle dollar signs in filenames here (grumble, grumble...)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import shutil \n",
    "\n",
    "# Ghostscript executable is inside the container.\n",
    "# TEMPLATE: gs -dBATCH -dNOPAUSE -dQUIET -sDEVICE=png16m -sOutputFile=/scratch/test/output/test-%d.png -r300 /scratch/test/germanocr.pdf\n",
    "SINGULARITYCMD = 'singularity exec -B {}:/scratch/ /global/scratch/mmanning/tesseract4.img ' \n",
    "GHOSTSCRIPTCMD = 'gs -dBATCH -dNOPAUSE -dQUIET -sDEVICE=png16m -sOutputFile=\\\"{}-%d.png\\\" -r300 \\\"{}\\\" ;  echo $?'\n",
    "\n",
    "os.chdir(scratchDataDirectory)\n",
    "print ('current working directory: ', os.getcwd())\n",
    "\n",
    "scmd = SINGULARITYCMD.format(scratchDataDirectory)\n",
    "\n",
    "# total number of ghostscript tasks\n",
    "gsCommandTotal = 0\n",
    "\n",
    "with open(gsCommandScript, 'w') as f:  \n",
    "\n",
    "    for entry in scantreeForFiles(scratchDataDirectory):\n",
    "        filename, file_extension = os.path.splitext(entry)\n",
    "        if ( entry.endswith('.pdf')):\n",
    "            relativepath1 = entry[len(scratchDataDirectory):]\n",
    "            relativepath2 = filename[len(scratchDataDirectory):]\n",
    "            gcmd = GHOSTSCRIPTCMD.format(tesseractScratchDataDirectory+relativepath2, tesseractScratchDataDirectory+relativepath1 )\n",
    "            f.write(scmd + gcmd + '\\n')\n",
    "            gsCommandTotal += 1\n",
    "    \n",
    "    \n",
    "#set time limit for this batch run\n",
    "outputbatchscript = batchtemplate.format('04:30:00',  gsCommandScript)\n",
    "with open(slurmScript, 'w') as f:  \n",
    "    f.write(outputbatchscript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Execute the task script with ht_helper__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(runFolder)\n",
    "print ('current working directory: ', os.getcwd())\n",
    "\n",
    "out = !sbatch slurmscript.sh   \n",
    "    \n",
    "print ('Execute ghostscript output: ', out ) \n",
    "jobId =  out[0].split()[3]\n",
    "print (jobId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the users queue and the job status by id\n",
    "!squeue -u $username\n",
    "print('--------------------------------')\n",
    "!scontrol show job $jobId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Check all task log files for bad exit code__  \n",
    "task numbers align with lines in the task script  \n",
    "check the log file of tasks in the returned array of failures  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob, os\n",
    "print ('current working directory: ', os.getcwd())\n",
    "\n",
    "jobId = '1339347'\n",
    "gsCommandTotal = 2761\n",
    "\n",
    "fileroot = projectname + '.' + jobId + '.log'\n",
    "tasklist = validateTaskResults(fileroot, gsCommandTotal)\n",
    "print ('these tasks in task script failed: ', tasklist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove task logs after any errors have been resolved__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " \n",
    "filter = fileroot + '*'\n",
    "print ('filter: ', filter)\n",
    "#for f in glob.glob(filter):\n",
    "#    os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create script to ocr all png files in working directory to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob, os\n",
    "os.chdir(scratchDataDirectory)\n",
    "print ('current working directory: ', os.getcwd())\n",
    "# template: tesseract --tessdata-dir /opt/tessdata /scratch/germanocr_Page_01.png  germanout  -l deu\n",
    "TCMD = '  tesseract --tessdata-dir /opt/tessdata \\\"{}\\\" \\\"{}\\\"  -l eng;  echo $?'\n",
    "#\n",
    "\n",
    "scmd = SINGULARITYCMD.format(scratchDataDirectory)\n",
    "# total number of tesseract tasks\n",
    "t4CommandTotal = 0\n",
    "\n",
    "with open(t4CommandScript, 'w') as f:\n",
    "\n",
    "    for entry in scantreeForFiles(scratchDataDirectory):\n",
    "        if ( entry.endswith('.png')):\n",
    "            filename, file_extension = os.path.splitext(entry)\n",
    "            relativepath1 = entry[len(scratchDataDirectory):]\n",
    "            relativepath2 = filename[len(scratchDataDirectory):]\n",
    "            tcmd = TCMD.format(tesseractScratchDataDirectory+relativepath1, tesseractScratchDataDirectory+relativepath2 )\n",
    "            #print(scmd + tcmd)\n",
    "            f.write(scmd + tcmd + '\\n')\n",
    "            t4CommandTotal += 1\n",
    "    \n",
    "    \n",
    "#set time limit for this batch run\n",
    "outputbatchscript = batchtemplate.format('15:00:00',  t4CommandScript)\n",
    "with open(slurmScript, 'w') as f:  \n",
    "    f.write(outputbatchscript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Execute the task script with ht_helper__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(runFolder)\n",
    "print ('current working directory: ', os.getcwd())\n",
    "\n",
    "out = !sbatch slurmscript.sh   \n",
    "    \n",
    "print ('Execute tesseract4 output: ', out ) \n",
    "jobId =  out[0].split()[3]\n",
    "print (jobId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the users queue and the job status by id\n",
    "!squeue -u $username\n",
    "print('--------------------------------')\n",
    "!scontrol show job $jobId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Check all task log files for bad exit code__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(runFolder)\n",
    "print ('current working directory: ', os.getcwd())\n",
    "\n",
    "fileroot = projectname + '.' + jobId + '.log'\n",
    "#tasklist = validateTaskResults(fileroot, 10) first check a small subset\n",
    "tasklist = validateTaskResults(fileroot, t4CommandTotal)\n",
    "print ('these tasks in task script failed: ', tasklist)\n",
    "\n",
    "# Remove task logs\n",
    "#filter = fileroot + '*'\n",
    "#for f in glob.glob(filter):\n",
    "#    os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge text files and upload to Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scandir import scandir\n",
    "dirlist = []\n",
    "\n",
    "scandirForFolders(scratchDataDirectory, dirlist)\n",
    "\n",
    "print(\"num dirs: \", len(dirlist) ) \n",
    "\n",
    "for x in range(0, 10): \n",
    "    print(\"dir: \", dirlist[x] ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__check that for every .png there is a .txt in each directory__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missingResultList = []\n",
    "for currentdir in dirlist:\n",
    "    os.chdir(currentdir)\n",
    "    #print ('current working directory: ', os.getcwd())\n",
    "    \n",
    "    \n",
    "    # get a list of all pdf names\n",
    "    for filename in os.listdir(os.getcwd()):\n",
    "        if  os.path.isfile(filename)  and filename.endswith('.png'):\n",
    "            fn, fe = os.path.splitext(filename)\n",
    "            if not os.path.exists(fn + '.txt'):\n",
    "                missingResultList.append(currentdir + '/' + filename)\n",
    "                print ('missing result: ', currentdir + '/' + filename )\n",
    "print(\"missingResultList size: \", len(missingResultList) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "__merge text files into original documents__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "for currentdir in dirlist:\n",
    "    os.chdir(currentdir)\n",
    "    #print ('current working directory: ', os.getcwd())\n",
    "    pdfnamelist = []\n",
    "    \n",
    "    # get a list of all pdf names\n",
    "    for filename in os.listdir(os.getcwd()):\n",
    "        if  os.path.isfile(filename)  and filename.endswith(\".pdf\"):\n",
    "            #print(\"filename: \", filename ) \n",
    "            fn, fe = os.path.splitext(filename)\n",
    "            pdfnamelist.append(fn)\n",
    "    #print(\"pdfnamelist size: \", len(pdfnamelist) ) \n",
    "    \n",
    "    for name in pdfnamelist:\n",
    "        mergeList = []\n",
    "        for filename in os.listdir('.'):\n",
    "            \n",
    "            if filename.endswith(\".txt\") and filename.startswith(name): \n",
    "                #print(\"filename: \", filename)\n",
    "                mergeList.append(filename)\n",
    "                \n",
    "        #print('mergeList: ', mergeList)\n",
    "        alltextfilename = ''.join([ currentdir,\"/\",name,'_ALL.txt'])\n",
    "        \n",
    "        if (len(mergeList) > 1):\n",
    "            sortedList = sorted(mergeList, key = natural_sort_key)\n",
    "            print('sortedList: ', sortedList)\n",
    "\n",
    "            alltextfilename = ''.join([ currentdir,\"/\",name,'_ALL.txt'])\n",
    "            with open(alltextfilename, 'w', encoding=\"utf-8\") as outfile:\n",
    "                for fname in sortedList:\n",
    "                    with open(''.join([currentdir,\"/\", fname]), encoding=\"utf-8\" ) as infile:\n",
    "                        for line in infile:\n",
    "                            outfile.write(line)\n",
    "        elif (len(mergeList) == 1):\n",
    "            # if file is only one page, just copy to _ALL.txt so it is included in results\n",
    "            print('single file: ', mergeList[0])\n",
    "            copyfile(mergeList[0], alltextfilename)\n",
    "        else: \n",
    "            print('empty mergeList on file: ', name)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__verify counts__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(scratchDataDirectory)\n",
    "print(\"number of pdfs in set: \" ) \n",
    "\n",
    "!find . -name \"*.pdf\" | wc -l\n",
    "\n",
    "print(\"number of merged text files in set: \" ) \n",
    "\n",
    "!find . -name \"*_ALL.txt\" | wc -l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"num dirs: \", len(dirlist) ) \n",
    "\n",
    "for currentdir in dirlist:\n",
    "    os.chdir(currentdir)\n",
    "    print ('current working directory: ', os.getcwd())\n",
    "    \n",
    "    # remove all pdf and png files\n",
    "    for currentFile in os.listdir(os.getcwd()):\n",
    "        if os.path.isfile(currentFile) and not currentFile.endswith('_ALL.txt'):\n",
    "                os.remove(os.path.join(currentdir, currentFile))\n",
    "    \n",
    "    for currentFile in os.listdir(os.getcwd()):\n",
    "        if os.path.isfile(currentFile) :\n",
    "            newname = currentFile.replace('_ALL.txt', '.txt')\n",
    "            os.rename(currentFile, newname)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "os.chdir(scratchDataDirectory)\n",
    "print ('current working directory: ', os.getcwd())\n",
    "shutil.make_archive(projectname, 'zip', scratchDataDirectory)\n",
    "\n",
    "print('completed zip: ', os.stat(projectname + '.zip'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Move the resulting zip file to Box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#folderId = find_folder_id(boxProjectFolder)\n",
    "folderId = find_folder_id('ThisIsATest')\n",
    "print (\"folderId: \", folderId )\n",
    "upload_folder = client.folder(folder_id=folderId).get()\n",
    "objUploaded = upload_folder.upload(scratchDataDirectory + projectname + '.zip')  \n",
    "print (\"obj file id: \", objUploaded['id'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
